{"unk_token": "<|endoftext|>", "bos_token": "<|endoftext|>", "eos_token": "<|endoftext|>", "add_prefix_space": false, "model_max_length": 1024, "special_tokens_map_file": null, "name_or_path": "gpt2-medium", "additional_special_tokens": ["<genre>", "<artist>", "<title>", "<emotions>", "<topics>", "<lyrics>", "<lang>", "</lyrics>", "<chorus>", "<block_end>", "<sentence_end>", "<continue>", "<generated>", "<num_syllables>"], "tokenizer_class": "GPT2Tokenizer"}